{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/henryhuang/3rd Year/research/brain-hci/team-text-analysis/venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Users/henryhuang/3rd Year/research/brain-hci/team-text-analysis/venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in /Users/henryhuang/3rd Year/research/brain-hci/team-text-analysis/venv/lib/python3.10/site-packages (3.1.5)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/henryhuang/3rd Year/research/brain-hci/team-text-analysis/venv/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/henryhuang/3rd Year/research/brain-hci/team-text-analysis/venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/henryhuang/3rd Year/research/brain-hci/team-text-analysis/venv/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: et-xmlfile in /Users/henryhuang/3rd Year/research/brain-hci/team-text-analysis/venv/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/henryhuang/3rd Year/research/brain-hci/team-text-analysis/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/henryhuang/3rd Year/research/brain-hci/team-text-analysis/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcription data and CATA dictionary\n",
    "tx_file = \"data/CSL_Laptop_Group1_word_level_transcriptions.csv\"\n",
    "dict_file = \"data/cata-dict.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df = pd.read_csv(tx_file)\n",
    "dictionary_df = pd.read_excel(dict_file, sheet_name='Marks_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.684</td>\n",
       "      <td>2.784</td>\n",
       "      <td>Okay,</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.506</td>\n",
       "      <td>5.967</td>\n",
       "      <td>nevermind.</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.987</td>\n",
       "      <td>6.027</td>\n",
       "      <td>Do</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.549</td>\n",
       "      <td>11.350</td>\n",
       "      <td>you</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.235</td>\n",
       "      <td>18.675</td>\n",
       "      <td>see</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start     end        text     speaker\n",
       "0   1.684   2.784       Okay,  SPEAKER_00\n",
       "1   5.506   5.967  nevermind.  SPEAKER_01\n",
       "2   5.987   6.027          Do  SPEAKER_01\n",
       "3   9.549  11.350         you  SPEAKER_01\n",
       "4  18.235  18.675         see  SPEAKER_01"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>diction_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(:</td>\n",
       "      <td>P33_IAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i like*</td>\n",
       "      <td>P30_INTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(should not) like</td>\n",
       "      <td>N30_INTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>they like*</td>\n",
       "      <td>P30_INTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we like*</td>\n",
       "      <td>P30_INTER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               words diction_code\n",
       "0                 (:      P33_IAM\n",
       "1            i like*    P30_INTER\n",
       "2  (should not) like    N30_INTER\n",
       "3         they like*    P30_INTER\n",
       "4           we like*    P30_INTER"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only save the words and diction_code columns\n",
    "dictionary_df = dictionary_df[['words', 'diction_code']]\n",
    "dictionary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract category-wise words, handling wildcards and context-based words\n",
    "category_words = defaultdict(set)  # Stores direct words (key: category, value: set of words)\n",
    "category_patterns = defaultdict(list)  # Stores regex patterns and context-based words\n",
    "\n",
    "for _, row in dictionary_df.iterrows():\n",
    "    word = str(row['words']).strip().lower()  # Normalize word\n",
    "    category = row['diction_code']\n",
    "    \n",
    "    # Skip negative diction codes\n",
    "    if category[0]== 'N':\n",
    "        continue\n",
    "\n",
    "    # Handle wildcard \"*\"\n",
    "    if '*' in word:\n",
    "        regex_pattern = re.sub(r'\\*', r'.*', word)  # Convert * to regex pattern\n",
    "        category_patterns[category].append(re.compile(regex_pattern))\n",
    "    else:\n",
    "        category_words[category].add(word)  # Store as a normal word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: P33_IAM, Words: ['kind', 'optimistic', 'cuter', 'comforting', 'commiserates']\n",
      "Category: P30_INTER, Words: ['peacefully', 'amity', 'dude', 'heartening', 'lovelier']\n",
      "Category: P10_TRANS, Words: ['designed', 'directions', 'depiction', 'quests', 'gauge']\n",
      "Category: P100_OVERALL, Words: ['write', 'situation', 'tryin', 'major', 'equilize']\n",
      "Category: P21_AMP, Words: ['producing', 'achieves', 'achievement', 'updating', 'accomplishes']\n",
      "Category: P20_ACT, Words: ['avails', 'refill', 'remote', 'executed', 'react']\n",
      "Category: P11_TMA, Words: ['adjustable', 'routes', 'ad-libbing', 'stage', 'subject']\n",
      "Category: P13_TSF, Words: ['developes', 'deadline', 'scheme', 'elements', 'schemes']\n",
      "Category: P31_ICM, Words: ['moderation', 'reconciles', 'arbitrators', 'conform', 'assents']\n",
      "Category: P23_ATM, Words: ['takes-care', 'takes-over', 'aids', 'conducting', 'workload-sharing']\n",
      "Category: P24_ACO, Words: ['combine', 'intermixed', 'conjoined', 'grouping', 'divides']\n",
      "Category: P32_IMO, Words: ['gorgeous', 'excellently', 'spurred', 'excellent', 'excitement']\n",
      "Category: P22_ASM, Words: ['diminishes', 'measure', 'restored', 'deterioration', 'decreases']\n",
      "Category: P12_TGS, Words: ['requesting', 'objective', 'order', 'sketches', 'direction']\n",
      "Category: P30_INTER, Patterns: 91 patterns\n",
      "  Pattern: i like.*\n",
      "  Pattern: they like.*\n",
      "  Pattern: we like.*\n",
      "  Pattern: will like.*\n",
      "  Pattern: you like.*\n",
      "Category: P33_IAM, Patterns: 32 patterns\n",
      "  Pattern: accepta.*\n",
      "  Pattern: affection.*\n",
      "  Pattern: amus.*\n",
      "  Pattern: appreciat.*\n",
      "  Pattern: bless.*\n",
      "Category: P100_OVERALL, Patterns: 18 patterns\n",
      "  Pattern: agreement.*\n",
      "  Pattern: benefic.*\n",
      "  Pattern: benefitt.*\n",
      "  Pattern: bonus.*\n",
      "  Pattern: credit.*\n",
      "Category: P32_IMO, Patterns: 20 patterns\n",
      "  Pattern: amaze.*\n",
      "  Pattern: assur.*\n",
      "  Pattern: brilliance.*\n",
      "  Pattern: courag.*\n",
      "  Pattern: determina.*\n",
      "Category: P10_TRANS, Patterns: 24 patterns\n",
      "  Pattern: anticipat.*\n",
      "  Pattern: approv.*\n",
      "  Pattern: ease.*\n",
      "  Pattern: expect.*\n",
      "  Pattern: forbod.*\n",
      "Category: P31_ICM, Patterns: 4 patterns\n",
      "  Pattern: defend.*\n",
      "  Pattern: forgiv.*\n",
      "  Pattern: harmless.*\n",
      "  Pattern: harmon.*\n",
      "Category: P12_TGS, Patterns: 1 patterns\n",
      "  Pattern: desir.*\n",
      "Category: P20_ACT, Patterns: 15 patterns\n",
      "  Pattern: divin.*\n",
      "  Pattern: engag.*\n",
      "  Pattern: freed.*\n",
      "  Pattern: helper.*\n",
      "  Pattern: oh.*\n",
      "Category: P11_TMA, Patterns: 1 patterns\n",
      "  Pattern: opportunit.*\n",
      "Category: P21_AMP, Patterns: 1 patterns\n",
      "  Pattern: succeed.*\n"
     ]
    }
   ],
   "source": [
    "# View the categories and their words\n",
    "for category, words in category_words.items():\n",
    "    print(f\"Category: {category}, Words: {list(words)[:5]}\")  # Display first 5 words for brevity\n",
    "\n",
    "for category, patterns in category_patterns.items():\n",
    "    print(f\"Category: {category}, Patterns: {len(patterns)} patterns\")\n",
    "    for pattern in patterns[:5]:\n",
    "        print(f\"  Pattern: {pattern.pattern}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.684</td>\n",
       "      <td>2.784</td>\n",
       "      <td>[okay]</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.506</td>\n",
       "      <td>5.967</td>\n",
       "      <td>[nevermind]</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.987</td>\n",
       "      <td>6.027</td>\n",
       "      <td>[do]</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.549</td>\n",
       "      <td>11.350</td>\n",
       "      <td>[you]</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.235</td>\n",
       "      <td>18.675</td>\n",
       "      <td>[see]</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start     end         text     speaker\n",
       "0   1.684   2.784       [okay]  SPEAKER_00\n",
       "1   5.506   5.967  [nevermind]  SPEAKER_01\n",
       "2   5.987   6.027         [do]  SPEAKER_01\n",
       "3   9.549  11.350        [you]  SPEAKER_01\n",
       "4  18.235  18.675        [see]  SPEAKER_01"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess transcript\n",
    "transcript_df = transcript_df[['start', 'end', 'text', 'speaker']].dropna()\n",
    "transcript_df['text'] = transcript_df['text'].str.lower().apply(lambda x: re.findall(r'\\b\\w+\\b', x))\n",
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define window params\n",
    "window_size = 30    # 30-second window\n",
    "step_size   = 15    # 15-second overlap step\n",
    "max_time    = transcript_df['end'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P100_OVERALL',\n",
       " 'P10_TRANS',\n",
       " 'P11_TMA',\n",
       " 'P12_TGS',\n",
       " 'P13_TSF',\n",
       " 'P20_ACT',\n",
       " 'P21_AMP',\n",
       " 'P22_ASM',\n",
       " 'P23_ATM',\n",
       " 'P24_ACO',\n",
       " 'P30_INTER',\n",
       " 'P31_ICM',\n",
       " 'P32_IMO',\n",
       " 'P33_IAM'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create time series data structures\n",
    "time_points = np.arange(0, max_time, step_size)\n",
    "speaker_time_series = []  # Will hold (speaker, window_start, window_end, category_counts...)\n",
    "all_categories = set(category_words.keys()) | set(category_patterns.keys())\n",
    "all_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in time_points:\n",
    "    window_start = t\n",
    "    window_end   = t + window_size\n",
    "    \n",
    "    # Filter transcript rows overlapping this window\n",
    "    # Condition: utterance overlaps if start < window_end and end >= window_start\n",
    "    df_window = transcript_df[\n",
    "        (transcript_df['start'] < window_end) &\n",
    "        (transcript_df['end']   >= window_start)\n",
    "    ]\n",
    "    \n",
    "    # We'll keep track of counts for each speaker → each category\n",
    "    # e.g., speaker_category[speaker][category] = count\n",
    "    speaker_category = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    # For each row, tokenize and match words\n",
    "    for _, row in df_window.iterrows():\n",
    "        speaker = row['speaker']\n",
    "        \n",
    "        # Tokenize text (lowercase, alphanumeric)\n",
    "        tokens = re.findall(r'\\b\\w+\\b', str(row['text']).lower())\n",
    "        \n",
    "        # Match direct words\n",
    "        for cat, words_set in category_words.items():\n",
    "            for token in tokens:\n",
    "                if token in words_set:\n",
    "                    speaker_category[speaker][cat] += 1\n",
    "        \n",
    "        # Match wildcard/regex patterns\n",
    "        for cat, pattern_list in category_patterns.items():\n",
    "            for pat in pattern_list:\n",
    "                for token in tokens:\n",
    "                    if pat.match(token):\n",
    "                        speaker_category[speaker][cat] += 1\n",
    "    \n",
    "    # For each speaker we found in the current window, create a row\n",
    "    # that includes category counts for all categories.\n",
    "    # If a speaker has zero for a category, it won't appear in speaker_category,\n",
    "    # so we must fill in 0 for missing categories.\n",
    "    for speaker, cat_counts in speaker_category.items():\n",
    "        row_dict = {\n",
    "            'speaker': speaker,\n",
    "            'window_start': window_start,\n",
    "            'window_end':   window_end\n",
    "        }\n",
    "        # Make sure all categories appear\n",
    "        for cat in all_categories:\n",
    "            row_dict[cat] = cat_counts.get(cat, 0)\n",
    "\n",
    "        speaker_time_series.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "      <th>P100_OVERALL</th>\n",
       "      <th>P31_ICM</th>\n",
       "      <th>P21_AMP</th>\n",
       "      <th>P10_TRANS</th>\n",
       "      <th>P23_ATM</th>\n",
       "      <th>P30_INTER</th>\n",
       "      <th>P13_TSF</th>\n",
       "      <th>P32_IMO</th>\n",
       "      <th>P20_ACT</th>\n",
       "      <th>P12_TGS</th>\n",
       "      <th>P11_TMA</th>\n",
       "      <th>P24_ACO</th>\n",
       "      <th>P33_IAM</th>\n",
       "      <th>P22_ASM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPEAKER_03</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      speaker  window_start  window_end  P100_OVERALL  P31_ICM  P21_AMP  \\\n",
       "0  SPEAKER_00           0.0        30.0             1        0        0   \n",
       "1  SPEAKER_01           0.0        30.0             1        1        0   \n",
       "2  SPEAKER_01          15.0        45.0             1        0        0   \n",
       "3  SPEAKER_01          30.0        60.0             0        0        0   \n",
       "4  SPEAKER_03          30.0        60.0             0        0        0   \n",
       "\n",
       "   P10_TRANS  P23_ATM  P30_INTER  P13_TSF  P32_IMO  P20_ACT  P12_TGS  P11_TMA  \\\n",
       "0          0        0          0        0        0        0        0        0   \n",
       "1          0        0          1        0        0        1        0        0   \n",
       "2          0        0          1        0        0        0        0        0   \n",
       "3          0        1          0        0        0        0        0        0   \n",
       "4          0        0          0        0        0        1        0        0   \n",
       "\n",
       "   P24_ACO  P33_IAM  P22_ASM  \n",
       "0        0        0        0  \n",
       "1        0        0        0  \n",
       "2        0        0        0  \n",
       "3        0        0        0  \n",
       "4        0        0        0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_time_series_df = pd.DataFrame(speaker_time_series)\n",
    "speaker_time_series_df.sort_values(by=['window_start','speaker'], inplace=True)\n",
    "speaker_time_series_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker-level Time Series:\n",
      "      speaker  window_start  window_end  P100_OVERALL  P31_ICM  P21_AMP  \\\n",
      "0  SPEAKER_00           0.0        30.0             1        0        0   \n",
      "1  SPEAKER_01           0.0        30.0             1        1        0   \n",
      "2  SPEAKER_01          15.0        45.0             1        0        0   \n",
      "3  SPEAKER_01          30.0        60.0             0        0        0   \n",
      "4  SPEAKER_03          30.0        60.0             0        0        0   \n",
      "5  SPEAKER_01          45.0        75.0             5        0        1   \n",
      "6  SPEAKER_03          45.0        75.0             0        0        0   \n",
      "7  SPEAKER_01          60.0        90.0             5        0        1   \n",
      "8  SPEAKER_01          75.0       105.0             1        0        1   \n",
      "9  SPEAKER_01          90.0       120.0             1        0        1   \n",
      "\n",
      "   P10_TRANS  P23_ATM  P30_INTER  P13_TSF  P32_IMO  P20_ACT  P12_TGS  P11_TMA  \\\n",
      "0          0        0          0        0        0        0        0        0   \n",
      "1          0        0          1        0        0        1        0        0   \n",
      "2          0        0          1        0        0        0        0        0   \n",
      "3          0        1          0        0        0        0        0        0   \n",
      "4          0        0          0        0        0        1        0        0   \n",
      "5          2        1          2        0        0        1        0        0   \n",
      "6          0        0          0        0        0        1        0        0   \n",
      "7          2        0          2        0        0        1        0        0   \n",
      "8          0        0          1        0        0        1        0        0   \n",
      "9          0        0          1        0        0        1        0        0   \n",
      "\n",
      "   P24_ACO  P33_IAM  P22_ASM  \n",
      "0        0        0        0  \n",
      "1        0        0        0  \n",
      "2        0        0        0  \n",
      "3        0        0        0  \n",
      "4        0        0        0  \n",
      "5        0        0        0  \n",
      "6        0        0        0  \n",
      "7        0        0        0  \n",
      "8        0        0        0  \n",
      "9        0        0        0  \n",
      "\n",
      "Group-level Time Series:\n",
      "   window_start  window_end  P100_OVERALL  P31_ICM  P21_AMP  P10_TRANS  \\\n",
      "0           0.0        30.0             2        1        0          0   \n",
      "1          15.0        45.0             1        0        0          0   \n",
      "2          30.0        60.0             0        0        0          0   \n",
      "3          45.0        75.0             5        0        1          2   \n",
      "4          60.0        90.0             5        0        1          2   \n",
      "5          75.0       105.0             1        0        1          0   \n",
      "6          90.0       120.0             1        0        1          0   \n",
      "7         105.0       135.0             2        0        0          0   \n",
      "8         120.0       150.0             2        0        0          0   \n",
      "9         135.0       165.0             1        0        0          0   \n",
      "\n",
      "   P23_ATM  P30_INTER  P13_TSF  P32_IMO  P20_ACT  P12_TGS  P11_TMA  P24_ACO  \\\n",
      "0        0          1        0        0        1        0        0        0   \n",
      "1        0          1        0        0        0        0        0        0   \n",
      "2        1          0        0        0        1        0        0        0   \n",
      "3        1          2        0        0        2        0        0        0   \n",
      "4        0          2        0        0        1        0        0        0   \n",
      "5        0          1        0        0        1        0        0        0   \n",
      "6        0          1        0        0        1        0        0        0   \n",
      "7        0          1        0        0        0        0        0        0   \n",
      "8        0          1        0        0        0        0        0        0   \n",
      "9        0          1        0        0        1        0        0        0   \n",
      "\n",
      "   P33_IAM  P22_ASM                 speaker  \n",
      "0        0        0  SPEAKER_00, SPEAKER_01  \n",
      "1        0        0              SPEAKER_01  \n",
      "2        0        0  SPEAKER_01, SPEAKER_03  \n",
      "3        0        0  SPEAKER_01, SPEAKER_03  \n",
      "4        0        0              SPEAKER_01  \n",
      "5        0        0              SPEAKER_01  \n",
      "6        0        0              SPEAKER_01  \n",
      "7        0        0  SPEAKER_01, SPEAKER_05  \n",
      "8        0        0  SPEAKER_01, SPEAKER_05  \n",
      "9        0        0              SPEAKER_01  \n"
     ]
    }
   ],
   "source": [
    "# We can group by (window_start, window_end) and sum across speakers\n",
    "speaker_agg = lambda x: ', '.join(sorted(x.unique()))\n",
    "\n",
    "group_time_series_df = speaker_time_series_df.groupby(['window_start', 'window_end']).agg(\n",
    "    {**{col: 'sum' for col in speaker_time_series_df.columns if col not in ['window_start', 'window_end', 'speaker']},\n",
    "     'speaker': speaker_agg}\n",
    ").reset_index()\n",
    "\n",
    "group_time_series_df.to_csv(\"time_series_group_level.csv\", index=False)\n",
    "\n",
    "print(\"Speaker-level Time Series:\")\n",
    "print(speaker_time_series_df.head(10))\n",
    "\n",
    "print(\"\\nGroup-level Time Series:\")\n",
    "print(group_time_series_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
